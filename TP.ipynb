{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Arbre des Décision\n",
    "\n",
    "Modifié à partir d'un des TPs rendus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as il\n",
    "import src.class_Noeud\n",
    "import src.class_ArbreDecision\n",
    "import src.code_utils\n",
    "import src.test_utils as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe Noeud\n",
    "\n",
    "Un arbre (binaire dans le cas du TP) est composé de noeuds. On distingue deux types de noeuds :\n",
    " - les noeuds internes, qui ont des enfants\n",
    " - les feuilles, qui n'en ont pas\n",
    "\n",
    "Chaque noeud contient une référence vers le jeu de données ainsi que l'index de la colonne contenant le label.\n",
    "\n",
    "Il contient également des données qui le définissent :\n",
    " - les indices présents à ce niveau de l'arbre\n",
    " - la classe majoritaire parmi ces indices\n",
    " - l'erreur réalisée à supposer qu'on ne descende pas plus bas\n",
    "\n",
    "Si le noeud n'est pas une feuille, alors on stocke aussi des informations relatives au meilleur split trouvé :\n",
    " - l'index de l'attribut (parmi les colonnes)\n",
    " - le seuil (numérique ou ensembliste)\n",
    " - la valeur critique du paramètre alpha (cf. élagage)\n",
    " - des références aux sous-arbres gauche et droit (pointeurs sur racines)\n",
    "\n",
    "Cette structure \"fractale\" permet d'écrire naturellement des fonctions récursives. Elle évite le surcoût mémoire engendré par l'utilisation d'un tableau (efficace seulement pour les arbres binaires quasi-complets). En revanche le parcours des noeuds est plus complexe qu'avec un tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf5gbCExN_wk"
   },
   "outputs": [],
   "source": [
    "il.reload(src.class_Noeud); from src.class_Noeud import Noeud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe ArbreDecision\n",
    "\n",
    "Un arbre est composé d'un certain nombre de noeuds, organisés hiérarchiquement depuis un noeud racine. Ce dernier permettant de parcourir tout l'arbre, c'est le seul point d'entrée présent ici dans les champs de classe.\n",
    "\n",
    "Afin d'alléger les appels de fonctions, on passe également le jeu de données (par référence) ainsi que l'index de la colonne contenant le label.\n",
    "\n",
    "Le critère de split est stocké à ce niveau car il définit la structure de l'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf5gbCExN_wk"
   },
   "outputs": [],
   "source": [
    "il.reload(src.class_ArbreDecision); from src.class_ArbreDecision import ArbreDecision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déroulement de l'algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le constructeur d'ArbreDecision prend trois paramètres : un jeu de données au format pandas.DataFrame, l'index de la colonne contenant le label (de n'importe quel type), et le critère de split : 'g' pour Gini, 'e' pour entropy ou 'm' pour \"misclassification error\".\n",
    "\n",
    "Le type des données (hors label) est déterminé à la lecture des données : s'il y a quelque chose qui n'est pas un nombre, tout est considéré comme chaîne de caractères. Sinon, on considère qu'un attribut est entier s'il ne prend que des valeurs entières, et flottant dans le cas contraire. L'utilisateur peut également spécifier les types en passant en dernier paramètre un dictionnaire index $\\rightarrow$ type (\"str\", \"float\" ou \"int\").\n",
    "\n",
    "Une fois créé, un arbre ne contient qu'un seul noeud vide : sa racine. Un noeud contient toujours une référence au jeu de données complet, un ensemble d'indices correspondant aux individus à ce niveau de l'arbre (donc $[1, n]$ à la racine), et l'index du label. L'apprentissage via la fonction ArbreDecision.learn() consiste à\n",
    " 1. déterminer le meilleur split à la racine\n",
    " 2. l'appliquer pour obtenir deux noeuds enfants\n",
    " 3. déterminer la meilleure division dans chaque noeud enfant\n",
    " 4. l'appliquer dans chaque noeud enfant, etc (récursivement).\n",
    "\n",
    "Voir Noeud.learn(). Les deux fonctions principales sont donc Noeud.get_best_split() et Noeud.do_split(). La première prend en argument un critère et cherche pour chaque attribut à maximiser le gain d'information (= minimiser le critère qui lui mesure le manque d'information). Elle retourne un seuil ainsi qu'un numéro d'attribut, pris au hasard parmi les meilleures coupes trouvées. Noeud.do_split() retourne deux sous-ensembles d'indices correspondants au seuil choisi. Une fois de retour dans la fonction d'apprentissage, on crée alors deux noeuds enfants avec ces sous-ensembles, puis on cherche à les diviser, etc (procédure récursive).\n",
    "\n",
    "La recherche de la meilleure coupure s'effectue naturellement pour les variables numériques en triant d'abord la colonne correspondante, donnant a priori $n-1$ splits potentiels (= les inter-valeurs). Attention il peut y en avoir moins en présence de doublons. Concernant les variables symboliques, on cherche d'abord la modalité séparant le mieux les données, puis on cherche à y adjoindre une autre modalité, etc, tout pendant que la valeur du critère diminue. Exemple : (a/1 a/1 b/1 b/1 c/2 c/2 ...) avec label dans $\\{1, 2\\}$, et attribut à quatre modalités $\\{a, b, c, d\\}$. L'algorithme évalue d'abord le split $a$ vs. $\\{b, c, d\\}$, puis essaye de \"fusionner\" $a$ et $b$ : cela mène en effet à un critère plus bas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tient compte des valeurs manquantes à trois niveaux :\n",
    " - dans la fonction Noeud.get_best_split()\n",
    " - dans la fonction Noeud.do_split()\n",
    " - pour la prédiction (Noeud.predict())\n",
    "\n",
    "Lors de la recherche de la meilleure division, on ignore simplement les lignes auxquelles il manque la valeur d'attribut courante. Ces lignes sont dupliquées à gauche et à droite du seuil, afin de pénaliser la valeur du critère. En effet une colonne avec beaucoup de valeurs manquantes ne devrait pas être considérée $-$ idéalement l'utilisateur l'aura supprimée en amont.\n",
    "\n",
    "Au moment d'effectuer la division, une ligne avec attribut manquant est envoyée d'un côté déterminé par le tirage d'une variable aléatoire de Bernoulli. Le paramètre de cette loi est la proportion d'individus \"à gauche\" ayant le même label que celle à l'attribut manquant. C'est une manière assez simpliste de gérer les valeurs manquantes. rpart utilise plutôt les \"surrogate splits\" : voir par exemple vers le bas de [cette page](http://www.learnbymarketing.com/methods/classification-and-regression-decision-trees-explained/)\n",
    "\n",
    "Enfin, au niveau de la fonction de prédiction on retourne simplement un label au hasard parmi les classes majoritaires à ce stade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Élagage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une première idée d'application de la formule du cours (slides2, page 26) consiste à remonter l'arbre depuis les feuilles, en mettant à jour l'erreur globale + alpha x nombre de feuilles. On arrêterait de fusionner quand ce terme commence à croître. En plus de devoir spécifier une valeur de alpha, cette approche n'est pas très satisfaisante car elle nécessite d'effectuer un parcours \"bottom-up\" de l'arbre (il faudrait ajouter des pointeurs sur le noeud parent).\n",
    "\n",
    "En réfléchissant un peu à la formule, on en vient ensuite à une meilleure idée : après une fusion dans le cas d'un arbre binaire, on a enlevé exactement une feuille. Ce regroupement sera donc validé uniquement si alpha est inférieur ou égal à l'augmentation de l'erreur (en pourcentages). Le paramètre alpha critique d'un noeud correspond ainsi simplement à la différence entre son erreur et la somme de celles de ses enfants. Attention, cela est valable si l'on parcourt toujours l'arbre de bas en haut. Afin de rendre l'approche valide aussi dans l'autre sens, on modifie les valeurs alpha à chaque noeud $n$ : $\\alpha(n) \\leftarrow \\max(\\alpha(n), \\{ \\alpha(m), m \\texttt{ descendant de } n \\})$ (voir la fonction adjust_alpha()).\n",
    "\n",
    "Note : on peut exprimer alpha soit en absolu (équivaut alors à un nombre d'erreurs), soit en relatif (après division par $n$ : taux d'erreur). Cette dernière option est a priori préférable car on s'affranchit de la taille du jeu de données.\n",
    "\n",
    "Finalement, il suffit de s'arrêter lorsque l'alpha courant est inférieur strict à celui fournit en paramètre, que ce soit pour la prédiction ou pour l'affichage. L'arbre entier reste en mémoire, et on n'a pas besoin de créer d'autres arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf5gbCExN_wk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf5gbCExN_wk"
   },
   "outputs": [],
   "source": [
    "# Quelques fonctions utiles\n",
    "il.reload(t); pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques mots sur rpart\n",
    "\n",
    "La librairie R \"rpart\" que nous avons utilisée en TP réalise beaucoup plus de tâches que le code ci-dessus. Pour une comparaison juste, l'argument \"control\" sera fixé à la liste suivante :\n",
    "```r\n",
    "list(\n",
    "  minsplit = 2,\n",
    "  minbucket = 1,\n",
    "  maxcompete = 0,\n",
    "  maxsurrogate = 0,\n",
    "  usesurrogate = 0,\n",
    "  xval = 0,\n",
    "  surrogatestyle = 0,\n",
    "  maxdepth = 30)\n",
    "# avec cp = alpha (cf. code ci-dessus)\n",
    "```\n",
    "Voir ?rpart.control pour les détails.\n",
    "\n",
    "En l'état, ce code Python est de toutes façons beaucoup plus lent pour deux raisons :\n",
    " - il n'est pas compilé\n",
    " - il n'est pas écrit efficacement\n",
    "\n",
    "C'est pourquoi les timings devraient être calculés sur une réécriture en C $-$ à suivre.\n",
    "\n",
    "D'une manière générale les valeurs critiques trouvées pour alpha diffèrent entre mon code et rpart $-$ le calcul doit y être un peu différent. Le nombre de valeurs critiques est cependant à peu près le même, ce qui est tout de même rassurant, ainsi que l'ordre de grandeur des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"data/iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arbre est en général très simple (trois feuilles) pour un choix de alpha entre 0.01 et 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ArbreDecision(iris, 4, 'g') #indice de Gini\n",
    "a.learn()\n",
    "a.plot(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.eval_predict(a, iris, 0.05) #erreur de l'ordre de 4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces données sont tellement simples que l'erreur est souvent minimale pour l'arbre non élagué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.best_alpha(iris, 0.4, 4, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = pd.read_csv(\"data/tic-tac-toe.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'arbre est déjà plus complexe (et le temps d'apprentissage plus élevé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ArbreDecision(ttt, 9, 'e')\n",
    "a.learn()\n",
    "a.plot(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.eval_predict(a, ttt, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.best_alpha(ttt, 0.4, 9, 'e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données \"vais-je courir ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courir = pd.read_csv(\"data/courir.data\")\n",
    "courir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ArbreDecision(courir, 4, 'g')\n",
    "a.learn()\n",
    "a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme à l'arbre construit pendant l'examen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_alphas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet exemple (certes très artificiel) est intéressant car il montre les limites de l'élagage automatique. En effet fusionner les dernières feuilles augmente l'erreur d'exactement 1/10, et fusionner les feuilles résultantes l'augmente aussi de 0.1. On a donc seulement deux valeurs critiques de alpha : une qui élague tout sauf le split à la racine, et l'autre qui ne garde que la racine. Cependant, il semble intéressant de garder aussi le niveau intermédiaire \"retard oui / non\" ; mais sans intervention humaine c'est impossible à deviner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essayons avec un critère de split (en général) moins bon\n",
    "a = ArbreDecision(courir, 4, 'm')\n",
    "a.learn()\n",
    "a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le second split s'effectue toujours au seuil 25.25. Cela paraît étrange, car le calcul manuel de la valeur de split donne\n",
    " - $3/7 \\times (1 - 2/3) = 1/7$ au seuil 19\n",
    " - $6/7 \\times (1 - 5/6) = 1/7$ au seuil 25.25\n",
    "\n",
    "Alors alors, où est le bug ? En fait \"il n'y en a pas\" (sur ce point précis !). Une erreur d'arrondi favorise un split plutôt que l'autre :\n",
    "```python\n",
    ">>> (3/7) * (1 - 2/3)\n",
    "0.14285714285714288\n",
    ">>> (6/7) * (1 - 5/6)\n",
    "0.14285714285714282\n",
    "```\n",
    "\n",
    "Anecdotique puisque ce critère considérant les situations \"non vs. non + 5 x oui\" et \"4 x oui vs. oui + 2 x non\" équivalentes, il vaut mieux l'oublier. Intéressant en revanche pour des raisons numériques : les problèmes d'arrondis sont en effet fréquents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\"data/adult.data\", na_values=['?',''])\n",
    "a = ArbreDecision(adult, 11, 'g')\n",
    "a.learn()\n",
    "a.affiche(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.best_alpha(adult, 0.4, 11, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_test = pd.read_csv(\"data/adult.test\", na_values=['?',''])\n",
    "ap = a.predict(adult_test, 0.000358294518093873)\n",
    "np.mean(ap != adult_test.iloc[:,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve un taux d'erreur acceptable (16% au lieu de 14% dans mon ancien rapport, mais j'avais fait des réglages difficilement reproductibles et encore moins automatisables). Le temps de calcul est en revanche rédhibitoire : quelques minutes au lieu de quelques secondes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = pd.read_csv(\"data/letter-recognition.data\")\n",
    "a = ArbreDecision(letter, 0, 'e')\n",
    "a.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_alphas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.eval_predict(a, letter, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce taux d'erreur est conforme à celui renvoyé par rpart pour cette valeur de alpha. Légèrement inférieur même, ce qui semble indiquer que le critère basé sur l'entropie est préférable ici."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TpArbres.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
